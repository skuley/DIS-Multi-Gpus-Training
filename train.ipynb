{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3a432a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_lightning/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from model.isnet import DISNet, GtEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b916f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('saved_model/pretrained/isnet.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f59e9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Dict, Any\n",
    "\n",
    "bce_loss = nn.BCELoss()\n",
    "bce_w_loss = nn.BCEWithLogitsLoss()\n",
    "mse_loss = nn.MSELoss(reduction = \"mean\")\n",
    "\n",
    "def bce_loss_calc(gt_feature_maps, gt):\n",
    "    sum_loss = 0\n",
    "    for idx, output in enumerate(gt_feature_maps):\n",
    "        loss = bce_loss(component, gt)\n",
    "        sum_loss += loss\n",
    "    return sum_loss\n",
    "\n",
    "def feature_sync(gt_outputs, u2net_outputs):\n",
    "    loss_lst = []\n",
    "    for idx, gt_output in enumerate(gt_outputs):\n",
    "        loss = mse_loss(gt_output, u2net_outputs[idx])\n",
    "        loss_lst.append(loss)\n",
    "\n",
    "    loss = sum(loss_lst)\n",
    "    return loss\n",
    "\n",
    "    loss = nn.L1Loss()\n",
    "    return loss(input_data, target_data)\n",
    "\n",
    "class Net(pl.LightningModule):\n",
    "    def __init__(self, model, pretrained: str = None, lr: float = 0.001, epsilon: float = 1e-08, batch_size: int = 0) -> object:\n",
    "        super(Net, self).__init__()\n",
    "        self.lr = lr\n",
    "        self.epsilon = epsilon\n",
    "        self.net = model\n",
    "        self.gt_encoder = None\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        if pretrained:\n",
    "            state_dict = torch.load(pretrained, map_location='cpu')\n",
    "            self.net.load_state_dict(state_dict)\n",
    "            print('----------------------------------------------------------------------------------------------------')\n",
    "            print('pretrained loaded')\n",
    "            print('----------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    def load_gt_encoder(self, gt_encoder, pretrained: str = None):\n",
    "        self.gt_encoder = gt_encoder\n",
    "        if pretrained:\n",
    "            state_dict = torch.load(pretrained, map_location='cpu')\n",
    "            self.gt_encoder.load_state_dict(state_dict)\n",
    "            \n",
    "        self.gt_encoder.eval()\n",
    "        print('gt_encoder is loaded')\n",
    "        print('----------------------------------------------------------------------------------------------------')\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.u2net.parameters(), lr=self.lr, betas=(0.9, 0.999), eps=self.epsilon, weight_decay=0)\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        image, gt = batch['image'], batch['gt']\n",
    "        im_side_outputs, im_features = self.net(image)\n",
    "        loss = bce_loss(outputs, gt)\n",
    "        \n",
    "        if self.gt_encoder:\n",
    "            gt_side_outputs, gt_features = self.gt_encoder(gt)\n",
    "            fs_mse_loss = feat_sync(gt_features, im_features)\n",
    "            loss += fs_mse_loss\n",
    "        \n",
    "        self.log(f\"{stage}_loss\", loss, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._common_step(batch, batch_idx)\n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._common_step(batch, batch_idx)\n",
    "        self.val_loss = loss\n",
    "        return loss\n",
    "    \n",
    "#     def on_save_checkpoint(self, checkpoint: Dict[str, Any]) -> None:\n",
    "#         state_dict = checkpoint['state_dict']\n",
    "#         epoch = checkpoint['epoch']\n",
    "#         PATH = f'epoch={epoch}-val_loss={self.val_loss}-batch_size={self.batch_size}.pth'\n",
    "        \n",
    "#         key_word = 'net.'\n",
    "#         new_sd = OD()\n",
    "#         for key, value in state_dict.items():\n",
    "#             if key_word in key:\n",
    "#                 key = key.replace(key_word, '')\n",
    "#             new_sd[key] = value\n",
    "        \n",
    "#         # save .pth file seperately\n",
    "#         torch.save(new_sd, PATH)\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        image, gt = batch['image'], batch['gt']\n",
    "        return self.net(image)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c3b3dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DISNet Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "disnet = DISNet(3,1)\n",
    "gt_encoder = GtEncoder(1,1)\n",
    "disnet_pretrained = 'saved_model/pretrained/isnet.pth'\n",
    "\n",
    "net = Net(disnet, pretrained=disnet_pretrained)\n",
    "net.load_gt_encoder(gt_encoder, pretrained=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02183214",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# GTEncoder Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_encoder = GtEncoder(1,1)\n",
    "net = Net(gt_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e4e97c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Dataset GtEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e3485",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.gt_dataset import Dataset\n",
    "import albumentations as A\n",
    "\n",
    "input_size = 1280\n",
    "\n",
    "mask_transform = A.Compose([\n",
    "    A.Resize(width=input_size, height=input_size),\n",
    "    A.RandomCrop(width=1024, height=1024),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.8),\n",
    "    A.RandomRotate90(p=0.8)\n",
    "])\n",
    "\n",
    "image_transform = A.Compose([\n",
    "    A.CLAHE(p=0.8),\n",
    "    A.RandomBrightnessContrast(p=0.8),\n",
    "    A.RandomGamma(p=0.8)]\n",
    ")\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "tr_ds = Dataset(image_path='../data/DIS5K/DIS-TR/gt', transform=mask_transform)\n",
    "len(tr_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae118a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.Compose(mask_transform[1:])(image=im_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1df0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image_path = tr_ds.images[1200]\n",
    "im = Image.open(image_path).convert('L').resize((1024,1024))\n",
    "im_arr = np.array(im)\n",
    "Image.fromarray(im_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87741f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "data = tr_ds[0]\n",
    "display(Image.fromarray(data['image']))\n",
    "Image.fromarray(data['gt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7d580",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset DISNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ecb8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.isnet_dataset import Dataset\n",
    "import albumentations as A\n",
    "\n",
    "input_size = 1280\n",
    "\n",
    "mask_transform = A.Compose([\n",
    "    A.Resize(width=input_size, height=input_size),\n",
    "    A.RandomCrop(width=1024, height=1024),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.8),\n",
    "    A.RandomRotate90(p=0.8)\n",
    "])\n",
    "\n",
    "image_transform = A.Compose([\n",
    "    A.CLAHE(p=0.8),\n",
    "    A.RandomBrightnessContrast(p=0.8),\n",
    "    A.RandomGamma(p=0.8)]\n",
    ")\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "tr_ds = Dataset(image_path='../data/DIS5K/DIS-TR/im', gt_path='../data/DIS5K/DIS-TR/gt',\n",
    "                image_transform=image_transform,\n",
    "                gt_transform=mask_transform,\n",
    "                load_on_mem=True)\n",
    "len(tr_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dbf895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "data = tr_ds[0]\n",
    "display(Image.fromarray(data['image']))\n",
    "Image.fromarray(data['gt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90615ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "image = '../../dataset/DIS5K/DIS-TE2/gt/11#Furniture#10#Hammock#4770076989_523ea0e1fe_o.png'\n",
    "im = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "input_size = 1280\n",
    "mask_transform = A.Compose([\n",
    "    A.Resize(width=input_size, height=input_size),\n",
    "    A.RandomCrop(width=1024, height=1024),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.8),\n",
    "    A.RandomRotate90(p=0.8)\n",
    "])\n",
    "sample = mask_transform(image=im)\n",
    "im = sample['image']\n",
    "Image.fromarray(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302beb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(DISNet(3,1))\n",
    "net.load_from_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d5494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_lightning",
   "language": "python",
   "name": "pytorch_lightning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
